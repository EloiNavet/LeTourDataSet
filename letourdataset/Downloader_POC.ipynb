{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from requests_html import AsyncHTMLSession\n",
    "from bs4 import BeautifulSoup, Tag\n",
    "from io import StringIO\n",
    "from itertools import chain\n",
    "\n",
    "# Import asyncio\n",
    "import asyncio\n",
    "\n",
    "from rich.progress import track\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import aiohttp\n",
    "from typing import List, Dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Downloader:\n",
    "\tdef __init__(\n",
    "\t\tself,\n",
    "\t\thistory_page=\"https://www.letour.fr/en/history\",\n",
    "\t\theaders={\n",
    "\t\t\t\"Accept\": \"text/html\",\n",
    "\t\t\t\"User-Agent\": \"python-requests/1.2.0\",\n",
    "\t\t\t\"Accept-Charset\": \"utf-8\",\n",
    "\t\t\t\"accept-encoding\": \"deflate, br\",\n",
    "\t\t},\n",
    "\t) -> None:\n",
    "\t\tself._prefix = \"http://www.letour.fr\"\n",
    "\t\tself._links: list[str] = self._get_urls(history_page, headers)\n",
    "\t\tself._ranking_types = {\n",
    "\t\t\t# \"Individual (General)\": \"itg\",\n",
    "\t\t\t\"Individual (Stage)\": \"ite\",\n",
    "\t\t\t# \"Points (General)\": \"ipg\",\n",
    "\t\t\t\"Points (Stage)\": \"ipe\",\n",
    "\t\t\t# \"Climber (General)\": \"img\",\n",
    "\t\t\t\"Climber (Stage)\": \"ime\",\n",
    "\t\t\t# \"Youth (General)\": \"ijg\",\n",
    "\t\t\t\"Youth (Stage)\": \"ije\",\n",
    "\t\t\t# \"Combative (General)\": \"icg\",\n",
    "\t\t\t\"Combative (Stage)\": \"ice\",\n",
    "\t\t\t# \"Team (General)\": \"etg\",\n",
    "\t\t\t\"Team (Stage)\": \"ete\",\n",
    "\t\t}\n",
    "\n",
    "\tdef _get_urls(self, history_page: str, headers: dict[str, str]) -> list[str]:\n",
    "\t\tstring = str(\n",
    "\t\t\tBeautifulSoup(\n",
    "\t\t\t\trequests.get(history_page, allow_redirects=True, headers=headers).text,\n",
    "\t\t\t\t\"html.parser\",\n",
    "\t\t\t)\n",
    "\t\t)\n",
    "\t\tpattern = r'data-tabs-ajax=\"([^\"]+)\"'\n",
    "\t\tmatches = re.findall(pattern, string)\n",
    "\t\tmatches = matches[::-1]\n",
    "\t\tlogging.debug(\n",
    "\t\t\t\"Matches found in the history page:\\n{}\".format(\"\\n\".join(matches))\n",
    "\t\t)\n",
    "\t\treturn matches\n",
    "\n",
    "\tasync def run(self) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "\t\tstages_list: list[pd.DataFrame] = []\n",
    "\t\trankings_list: list[pd.DataFrame] = []\n",
    "\t\tall_rankings_list: list[pd.DataFrame] = []\n",
    "\t\tlogging.debug(\"Links:\\n{}\".format(\"\\n\".join(self._links)))\n",
    "\t\tfor link in track(self._links, \"Downloading historical data...\"):\n",
    "\t\t\tlogging.info(\"Downloading data from {}\".format(self._prefix + link))\n",
    "\t\t\tsoup, year, distance = self._get_soup_year_distance(self._prefix + link)\n",
    "\n",
    "\t\t\tlogging.info(\"Parsing data from {}\".format(self._prefix + link))\n",
    "\t\t\tstages = self._get_stages(soup, year, distance)\n",
    "\t\t\tfinal_rankings = self._get_rankings(soup)\n",
    "\n",
    "\t\t\tlogging.info(\"Fetching yearly TDF URLs from {}\".format(self._prefix + link))\n",
    "\t\t\tselections_urls = await self._fetch_yearly_tdf_urls(self._prefix + link)\n",
    "\t\t\tintermediate_rankings = await self._get_all_rankings(\n",
    "\t\t\t\tselections_urls[\"Ranking\"], list(stages[\"Stages\"])\n",
    "\t\t\t)\n",
    "\t\t\tstages_winners = self._get_stages_winners(selections_urls[\"Stages winners\"])\n",
    "\t\t\t# teams = self._get_teams(selections_urls[\"Starters\"])\n",
    "\t\t\tjersey_wearers = self._get_jersey_wearers(selections_urls[\"Jersey wearers\"])\n",
    "\n",
    "\t\t\t# Update the dataframe stages by merging on 'Stages' using the stages_winners dataframe and the jersey_wearers dataframe\n",
    "\t\t\tstages = pd.merge(stages, stages_winners, on=\"Stages\", how=\"left\")\n",
    "\t\t\t# Drop 'Parcours' column\n",
    "\t\t\tstages = stages.drop(columns=\"Parcours\")\n",
    "\t\t\tstages = pd.merge(stages, jersey_wearers, on=\"Stages\", how=\"left\")\n",
    "\t\t\t# Make the first letter of each word in the fields of the columns that contains 'Winner' or 'Jersey' in their names uppercase and the rest lowercase using title() method\n",
    "\t\t\tcols = [\n",
    "\t\t\t\tcol\n",
    "\t\t\t\tfor col in stages.columns\n",
    "\t\t\t\tif \"winner\" in col.lower() or \"jersey\" in col.lower()\n",
    "\t\t\t]\n",
    "\t\t\tstages[cols] = stages[cols].apply(lambda x: x.str.title())\n",
    "\t\t\t# stages['Team'] = stages['Winner of stage'].apply(lambda x: x.split('(')[1].replace(')', ''))\n",
    "\t\t\t# stages['Winner of stage'] = stages['Winner of stage'].apply(lambda x: x.split('(')[0].strip())\n",
    "\n",
    "\t\t\tlogging.info(\"Cleaning up data from {}\".format(self._prefix + link))\n",
    "\t\t\tdf_ranking, df_all_rankings, df_stage = self._cleanup(\n",
    "\t\t\t\tstages,\n",
    "\t\t\t\tfinal_rankings,\n",
    "\t\t\t\tintermediate_rankings,\n",
    "\t\t\t\tyear,\n",
    "\t\t\t\tdistance,\n",
    "\t\t\t)\n",
    "\t\t\tlogging.info(\"Data from {} cleaned up\".format(self._prefix + link))\n",
    "\t\t\tstages_list.append(df_stage)\n",
    "\t\t\trankings_list.append(df_ranking)\n",
    "\t\t\tall_rankings_list.append(df_all_rankings)\n",
    "\n",
    "\t\tlogging.debug(\"Stage list:\\n{}\".format(stages_list))\n",
    "\t\tlogging.debug(\"Ranking list:\\n{}\".format(rankings_list))\n",
    "\t\tdf_stages = pd.concat(stages_list, ignore_index=True)\n",
    "\t\tdf_rankings = pd.concat(rankings_list, ignore_index=True)\n",
    "\t\tdf_all_rankings = pd.concat(all_rankings_list, ignore_index=True)\n",
    "\n",
    "\t\treturn df_stages, df_rankings, df_all_rankings\n",
    "\n",
    "\tdef _get_soup_year_distance(self, link: str) -> tuple[Tag, int, int]:\n",
    "\t\tresult = requests.get(link, allow_redirects=True)\n",
    "\t\ttext = result.text\n",
    "\t\tstatus = result.status_code\n",
    "\t\tlogging.info(link + \" ==> HTTP STATUS = \" + str(status))\n",
    "\n",
    "\t\tsoup = BeautifulSoup(text, \"html.parser\")\n",
    "\t\tyear_tag = soup.find(\"h3\")\n",
    "\t\tif year_tag is None:\n",
    "\t\t\traise Exception(\"Could not parse year.\")\n",
    "\t\tyear = int(year_tag.text[-4:])\n",
    "\t\tdistance = soup.select(\"[class~=statsInfos__number]\")[1].contents\n",
    "\t\tdistance = int(str(distance[0]).replace(\" \", \"\"))\n",
    "\t\treturn soup, year, distance\n",
    "\n",
    "\tdef _get_stages(self, soup: Tag, year: int, distance: int) -> pd.DataFrame:\n",
    "\t\tselect_tag = soup.find(\"select\")\n",
    "\t\tif not isinstance(select_tag, Tag):\n",
    "\t\t\traise Exception(\"Can't find `select`.\")\n",
    "\n",
    "\t\tdf_stages = pd.DataFrame(\n",
    "\t\t\t[[year, distance, option.text] for option in select_tag.find_all(\"option\")],\n",
    "\t\t\tcolumns=[\"Year\", \"TotalTDFDistance\", \"Stage\"],\n",
    "\t\t)\n",
    "\n",
    "\t\t# For the column Stage, it is formated like 'Stage 1 : Paris > Lyon' (so \"Stage [Number of stage] : [Start city] > [End city]\")\n",
    "\t\t# We will split this column into 'Stage number', 'Start city' and 'End city'\n",
    "\t\tdef extract_stage_number(stage_str):\n",
    "\t\t\ttry:\n",
    "\t\t\t\treturn int(stage_str.split(\":\")[0].split(\" \")[1]) # Here we use flot since in the early editions of the TDF some stages are played two times which gives for example stages 13.1 and 13.2; without this, the column should be int\n",
    "\t\t\texcept (IndexError, ValueError):\n",
    "\t\t\t\tif \"Prologue\" in stage_str:\n",
    "\t\t\t\t\treturn 0  # There is a case where the stage 0 is in fact a 'prologue'\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\treturn float(stage_str.split(\":\")[0].split(\" \")[1])\n",
    "\t\t\t\t\texcept (IndexError, ValueError):\n",
    "\t\t\t\t\t\tlogging.warning(f\"Could not parse stage number from '{stage_str}' in year {year}.\")\n",
    "\t\t\t\t\t\treturn None\n",
    "\n",
    "\t\tdf_stages[\"Stage number\"] = df_stages[\"Stage\"].apply(extract_stage_number)\n",
    "\t\tdf_stages[\"Start\"] = df_stages[\"Stage\"].apply(\n",
    "\t\t\tlambda x: x.split(\":\")[1].split(\">\")[0].strip()\n",
    "\t\t)\n",
    "\t\tdf_stages[\"End\"] = df_stages[\"Stage\"].apply(\n",
    "\t\t\tlambda x: x.split(\":\")[1].split(\">\")[1].strip()\n",
    "\t\t)\n",
    "\t\tdf_stages.drop(columns=\"Stage\", inplace=True)\n",
    "\t\tdf_stages.rename(columns={\"Stage number\": \"Stages\"}, inplace=True)\n",
    "\t\tdf_stages = df_stages[[\"Year\", \"TotalTDFDistance\", \"Stages\", \"Start\", \"End\"]]\n",
    "\t\treturn df_stages\n",
    "\n",
    "\tdef _get_stages_winners(self, winners_link: str) -> pd.DataFrame:\n",
    "\t\tresponse = requests.get(winners_link)\n",
    "\t\tresponse.raise_for_status()\n",
    "\t\trank_html = response.content\n",
    "\t\tsoup = BeautifulSoup(rank_html, \"html.parser\")\n",
    "\t\tstages_winners = soup.find(\"table\")\n",
    "\t\thtml_string = str(stages_winners)\n",
    "\t\thtml_io = StringIO(html_string)\n",
    "\t\tdf_stages_winners = pd.read_html(html_io)[0]\n",
    "\t\tdf_stages_winners.drop(columns=\"Last km\", inplace=True)\n",
    "\t\treturn df_stages_winners\n",
    "\n",
    "\tdef _get_teams(self, starters_link: str) -> pd.DataFrame:\n",
    "\t\tresponse = requests.get(starters_link)\n",
    "\t\tresponse.raise_for_status()\n",
    "\t\tstarter_html = response.content\n",
    "\t\tsoup = BeautifulSoup(starter_html, \"html.parser\")\n",
    "\t\tcompetitors = []\n",
    "\t\tteam_blocks = soup.find(\"div\", class_=\"list list--competitors\").find_all(\n",
    "\t\t\t\"h3\", class_=\"list__heading\"\n",
    "\t\t)\n",
    "\n",
    "\t\tfor team_block in team_blocks:\n",
    "\t\t\tteam_name = team_block.text.strip()\n",
    "\t\t\tlist_box = team_block.find_next_sibling(\"div\", class_=\"list__box\")\n",
    "\t\t\tcompetitor_items = list_box.find_all(\"li\", class_=\"list__box__item\")\n",
    "\n",
    "\t\t\tfor item in competitor_items:\n",
    "\t\t\t\tbib = (\n",
    "\t\t\t\t\titem.find(\"span\", class_=\"bib\").text\n",
    "\t\t\t\t\tif item.find(\"span\", class_=\"bib\")\n",
    "\t\t\t\t\telse None\n",
    "\t\t\t\t)\n",
    "\t\t\t\tname = (\n",
    "\t\t\t\t\titem.find(\"a\", class_=\"runner__link\").text.strip()\n",
    "\t\t\t\t\tif item.find(\"a\", class_=\"runner__link\")\n",
    "\t\t\t\t\telse None\n",
    "\t\t\t\t)\n",
    "\t\t\t\tcountry = (\n",
    "\t\t\t\t\titem.find(\"span\", class_=\"flag js-display-lazy\")[\n",
    "\t\t\t\t\t\t\"data-class\"\n",
    "\t\t\t\t\t].split(\"--\")[-1]\n",
    "\t\t\t\t\tif item.find(\"span\", class_=\"flag js-display-lazy\")\n",
    "\t\t\t\t\telse None\n",
    "\t\t\t\t)\n",
    "\n",
    "\t\t\t\tif bib and name:\n",
    "\t\t\t\t\tcompetitors.append(\n",
    "\t\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\t\"Team\": team_name,\n",
    "\t\t\t\t\t\t\t\"Bib\": bib,\n",
    "\t\t\t\t\t\t\t\"Name\": name,\n",
    "\t\t\t\t\t\t\t\"Country\": country,\n",
    "\t\t\t\t\t\t}\n",
    "\t\t\t\t\t)\n",
    "\n",
    "\t\treturn pd.DataFrame(competitors)\n",
    "\n",
    "\tdef _get_jersey_wearers(self, jersey_link: str) -> pd.DataFrame:\n",
    "\t\tresponse = requests.get(jersey_link)\n",
    "\t\tresponse.raise_for_status()\n",
    "\t\tjersey_html = response.content\n",
    "\t\tsoup = BeautifulSoup(jersey_html, \"html.parser\")\n",
    "\t\tjersey_wearers = soup.find(\"table\")\n",
    "\t\thtml_string = str(jersey_wearers)\n",
    "\t\thtml_io = StringIO(html_string)\n",
    "\t\tdf_jersey_wearers = pd.read_html(html_io)[0]\n",
    "\t\tdf_jersey_wearers = df_jersey_wearers.dropna(axis=1, how='all')\n",
    "\t\tcols = [col for col in df_jersey_wearers.columns if \"jersey\" in col.lower()]\n",
    "\t\t# Convert the columns that contains 'jersey' in their names to string\n",
    "\t\tdf_jersey_wearers[cols] = df_jersey_wearers[cols].astype(str)\n",
    "\t\treturn df_jersey_wearers\n",
    "\n",
    "\tdef _add_bib_number(self, soup: Tag, df_rankings: pd.DataFrame) -> pd.DataFrame:\n",
    "\t\t# Manually add the bib numbers because they are not in the rankings table\n",
    "\t\tbibs = re.findall(r'data-bib=\"([^\"]+)\"', str(soup))\n",
    "\t\tbibs = [int(bib.replace(\"#\", \"\")) for bib in bibs]\n",
    "\t\tdf_rankings.insert(2, \"Rider No.\", bibs)\n",
    "\t\treturn df_rankings\n",
    "\n",
    "\tdef _get_rankings(self, soup: Tag) -> pd.DataFrame:\n",
    "\t\t\"\"\"Get the rankings for a given year\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\tsoup (Tag): BeautifulSoup object of the ranking page\n",
    "\n",
    "\t\tReturns:\n",
    "\t\t\tpd.DataFrame: DataFrame containing the rankings for the given year\n",
    "\t\t\"\"\"\n",
    "\t\trankingTable = soup.find(\"table\")\n",
    "\t\thtml_string = str(rankingTable)\n",
    "\t\thtml_io = StringIO(html_string)\n",
    "\t\tdf_rankings = pd.read_html(html_io)[0]\n",
    "\t\tself._add_bib_number(soup, df_rankings)\n",
    "\t\treturn df_rankings\n",
    "\n",
    "\t@staticmethod\n",
    "\tasync def _fetch(session: aiohttp.ClientSession, url: str) -> str:\n",
    "\t\tasync with session.get(url) as response:\n",
    "\t\t\tresponse.raise_for_status()\n",
    "\t\t\treturn await response.text()\n",
    "\n",
    "\tasync def _get_all_rankings(self, ranking_link: str, stages_numbers: list[float]) -> pd.DataFrame:\n",
    "\t\tstages: list[dict[dict[str, str]]] = []\n",
    "\t\tasync with aiohttp.ClientSession() as session:\n",
    "\t\t\ttasks = []\n",
    "\t\t\tfor stage_number in stages_numbers:\n",
    "\t\t\t\tfor ranking_type_name, ranking_type_idx in self._ranking_types.items():\n",
    "\t\t\t\t\tranking_url = f\"{ranking_link}?stage={stage_number}&type={ranking_type_idx}\"\n",
    "\t\t\t\t\ttasks.append(self._fetch(session, ranking_url))\n",
    "\t\t\t\t\t\n",
    "\t\t\t# Execute all requests concurrently\n",
    "\t\t\tresponses = await asyncio.gather(*tasks)\n",
    "\n",
    "\t\t\tresponse_idx = 0\n",
    "\t\t\tfor stage_number in stages_numbers:\n",
    "\t\t\t\tfor ranking_type_name, ranking_type_idx in self._ranking_types.items():\n",
    "\t\t\t\t\trank_html = responses[response_idx]\n",
    "\t\t\t\t\tresponse_idx += 1\n",
    "\t\t\t\t\trank_soup = BeautifulSoup(rank_html, \"html.parser\")\n",
    "\t\t\t\t\trankings: list[dict[str, str]] = []\n",
    "\n",
    "\t\t\t\t\t# Get the ranking table\n",
    "\t\t\t\t\tranking_table = rank_soup.find(\"table\", {\"class\": \"rankingTable rtable js-extend-target\"})\n",
    "\t\t\t\t\tif not ranking_table:\n",
    "\t\t\t\t\t\tlogging.info(f\"No ranking for {ranking_type_name} on stage {stage_number} (URL: {ranking_link}).\")\n",
    "\t\t\t\t\t\tcontinue\n",
    "\t\t\t\t\trows = ranking_table.find_all(\"tr\")\n",
    "\t\t\t\t\tif len(rows) <= 2:\n",
    "\t\t\t\t\t\t# First case 1- just the header so no data; 2- header and one row of data so no data\n",
    "\t\t\t\t\t\tlogging.info(f\"No ranking for {ranking_type_name} on stage {stage_number} (URL: {ranking_link}).\")\n",
    "\t\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\t\tfor row in rows[1:]:\n",
    "\t\t\t\t\t\tcols = row.find_all(\"td\")\n",
    "\t\t\t\t\t\tif \"ite\" in ranking_type_idx:\n",
    "\t\t\t\t\t\t\tranking = {\n",
    "\t\t\t\t\t\t\t\t\"Rank\": cols[0].text.strip(),\n",
    "\t\t\t\t\t\t\t\t\"Rider\": cols[1].text.strip(),\n",
    "\t\t\t\t\t\t\t\t\"Team\": cols[2].text.strip(),\n",
    "\t\t\t\t\t\t\t\t\"Times\": cols[3].text.strip(),\n",
    "\t\t\t\t\t\t\t}\n",
    "\t\t\t\t\t\t\tif len(cols) > 4:\n",
    "\t\t\t\t\t\t\t\tranking[\"Gap\"] = cols[4].text.strip()\n",
    "\t\t\t\t\t\t\tif len(cols) > 5:\n",
    "\t\t\t\t\t\t\t\tranking[\"B\"] = cols[5].text.strip()\n",
    "\t\t\t\t\t\t\tif len(cols) > 6:\n",
    "\t\t\t\t\t\t\t\tranking[\"P\"] = cols[6].text.strip()\n",
    "\t\t\t\t\t\telif \"ipe\" in ranking_type_idx:\n",
    "\t\t\t\t\t\t\tcheckpoint = None\n",
    "\t\t\t\t\t\t\tif len(cols) == 1:\n",
    "\t\t\t\t\t\t\t\tcheckpoint = cols[0].text.strip()\n",
    "\t\t\t\t\t\t\t\tcontinue\n",
    "\t\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\tranking = {\n",
    "\t\t\t\t\t\t\t\t\t\"Rank\": cols[0].text.strip(),\n",
    "\t\t\t\t\t\t\t\t\t\"Rider\": cols[1].text.strip(),\n",
    "\t\t\t\t\t\t\t\t\t\"Team\": cols[2].text.strip(),\n",
    "\t\t\t\t\t\t\t\t\t\"Points\": cols[3].text.strip(),\n",
    "\t\t\t\t\t\t\t\t\t\"Checkpoint\": checkpoint,\n",
    "\t\t\t\t\t\t\t\t}\n",
    "\t\t\t\t\t\t\t\tif len(cols) > 4:\n",
    "\t\t\t\t\t\t\t\t\tranking[\"B\"] = cols[4].text.strip()\n",
    "\t\t\t\t\t\telif \"ime\" in ranking_type_idx:\n",
    "\t\t\t\t\t\t\tcheckpoint = None\n",
    "\t\t\t\t\t\t\tif len(cols) == 1:\n",
    "\t\t\t\t\t\t\t\tcheckpoint = cols[0].text.strip()\n",
    "\t\t\t\t\t\t\t\tcontinue\n",
    "\t\t\t\t\t\t\tranking = {\n",
    "\t\t\t\t\t\t\t\t\"Rank\": cols[0].text.strip(),\n",
    "\t\t\t\t\t\t\t\t\"Rider\": cols[1].text.strip(),\n",
    "\t\t\t\t\t\t\t\t\"Team\": cols[2].text.strip(),\n",
    "\t\t\t\t\t\t\t\t\"Points\": cols[3].text.strip(),\n",
    "\t\t\t\t\t\t\t\t\"Checkpoint\": checkpoint,\n",
    "\t\t\t\t\t\t\t}\n",
    "\t\t\t\t\t\telif \"ije\" in ranking_type_idx or \"ice\" in ranking_type_idx:\n",
    "\t\t\t\t\t\t\tranking = {\n",
    "\t\t\t\t\t\t\t\t\"Rank\": cols[0].text.strip(),\n",
    "\t\t\t\t\t\t\t\t\"Rider\": cols[1].text.strip(),\n",
    "\t\t\t\t\t\t\t\t\"Team\": cols[2].text.strip(),\n",
    "\t\t\t\t\t\t\t\t\"Times\": cols[3].text.strip(),\n",
    "\t\t\t\t\t\t\t}\n",
    "\t\t\t\t\t\t\tif len(cols) > 4:\n",
    "\t\t\t\t\t\t\t\tranking[\"Gap\"] = cols[4].text.strip()\n",
    "\t\t\t\t\t\telif \"ete\" in ranking_type_idx:\n",
    "\t\t\t\t\t\t\tranking = {\n",
    "\t\t\t\t\t\t\t\t\"Rank\": cols[0].text.strip(),\n",
    "\t\t\t\t\t\t\t\t\"Team\": cols[1].text.strip(),\n",
    "\t\t\t\t\t\t\t\t\"Times\": cols[2].text.strip(),\n",
    "\t\t\t\t\t\t\t}\n",
    "\t\t\t\t\t\t\tif len(cols) > 3:\n",
    "\t\t\t\t\t\t\t\tranking[\"Gap\"] = cols[3].text.strip()\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\traise NotImplementedError(\n",
    "\t\t\t\t\t\t\t\tf\"Ranking type {ranking_type_name} not implemented\"\n",
    "\t\t\t\t\t\t\t)\n",
    "\n",
    "\t\t\t\t\t\tranking[\"Stages\"] = stage_number\n",
    "\t\t\t\t\t\tranking[\"Ranking type\"] = ranking_type_name\n",
    "\t\t\t\t\t\trankings.append(ranking)\n",
    "\t\t\t\t\tstages.append(rankings)\n",
    "\n",
    "\t\treturn pd.DataFrame(list(chain.from_iterable(stages)))\n",
    "\n",
    "\tasync def _fetch_yearly_tdf_urls(self, year_url: str) -> dict[str, str]:\n",
    "\t\tsession = AsyncHTMLSession()\n",
    "\t\tresponse = await session.get(year_url)\n",
    "\t\tawait response.html.arender(timeout=20)\n",
    "\n",
    "\t\tsoup = BeautifulSoup(response.html.html, \"html.parser\")\n",
    "\n",
    "\t\tbuttons = soup.find_all(\n",
    "\t\t\t\"button\", class_=\"tabs__item btn js-tabs-nested\"\n",
    "\t\t) + soup.find_all(\"button\", class_=\"tabs__item btn js-tabs-nested is-active\")\n",
    "\n",
    "\t\tselections_urls = {\n",
    "\t\t\tbutton.get_text(strip=True): f\"{self._prefix}{button['data-tabs-ajax']}\"\n",
    "\t\t\tfor button in buttons\n",
    "\t\t}\n",
    "\n",
    "\t\treturn selections_urls\n",
    "\n",
    "\tdef _cleanup(\n",
    "\t\tself,\n",
    "\t\tdf_stages: pd.DataFrame,\n",
    "\t\tdf_rankings: pd.DataFrame,\n",
    "\t\tdf_all_rankings: pd.DataFrame,\n",
    "\t\tyear: int,\n",
    "\t\tdistance: int,\n",
    "\t) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "\n",
    "\t\t# Odd years\n",
    "\t\tpoint_years = [1907, 1909, 1910, 1911, 1912]\n",
    "\t\tnull_years = [1905, 1906, 1908]\n",
    "\n",
    "\n",
    "\t\tfor df in [df_rankings, df_all_rankings]:\n",
    "\t\t\t# Remainder of df_rankings.columns : 'Rank', 'Rider', 'Rider No.', 'Team', 'Times', 'Gap', 'B', 'P'\n",
    "\t\t\t# Remainder of df_all_rankings.columns : 'Stages', 'Ranking type', 'CheckpointRank', 'Rider', 'Team', 'Times', 'Points', 'Gap', 'B', 'P', 'Rank', 'Checkpoint'\n",
    "\t\t\tdf[\"Year\"] = year\n",
    "\t\t\tdf[\"Distance (km)\"] = distance\n",
    "\t\t\tdf[\"Number of stages\"] = len(df_stages)\n",
    "\n",
    "\t\t\tdf[\"ResultType\"] = \"time\"\n",
    "\t\t\tdf.loc[df[\"Year\"].isin(null_years), \"ResultType\"] = \"null\"\n",
    "\t\t\tdf.loc[df[\"Year\"].isin(point_years), \"ResultType\"] = \"points\"\n",
    "\t\t\t\n",
    "\t\t\tif \"Times\" in df.columns:\n",
    "\t\t\t\tdf[\"TotalSeconds\"] = df[\"Times\"].apply(\n",
    "\t\t\t\t\tlambda x: self._get_seconds(x, \"Total\")\n",
    "\t\t\t\t)\n",
    "\t\t\telse:\n",
    "\t\t\t\tdf[\"TotalSeconds\"] = 0\n",
    "\t\t\tif \"Gap\" in df.columns:\n",
    "\t\t\t\tdf[\"GapSeconds\"] = df[\"Gap\"].apply(\n",
    "\t\t\t\t\tlambda x: self._get_seconds(x, \"Gap\")\n",
    "\t\t\t\t)\n",
    "\t\t\telse:\n",
    "\t\t\t\tdf[\"GapSeconds\"] = 0\n",
    "\t\t\t\n",
    "\t\t\tdf[\"TotalSeconds\"] = df[\"TotalSeconds\"].fillna(0).astype(int)\n",
    "\t\t\tdf[\"GapSeconds\"] = df[\"GapSeconds\"].fillna(0).astype(int)\n",
    "\n",
    "\t\t\tif year in [2006, 1997]:\n",
    "\t\t\t\ttmp = df[df[\"Year\"] == year].reset_index()\n",
    "\t\t\t\tif \"TotalSeconds\" not in df.columns:\n",
    "\t\t\t\t\tdf[\"TotalSeconds\"] = 0\n",
    "\t\t\t\tif \"GapSeconds\" not in df.columns:\n",
    "\t\t\t\t\tdf[\"GapSeconds\"] = 0\n",
    "\t\t\t\tts = np.array(tmp[\"TotalSeconds\"])\n",
    "\t\t\t\tgs = np.array(tmp[\"GapSeconds\"])\n",
    "\t\t\t\tts[1:] = ts[0] + gs[1:]\n",
    "\t\t\t\tdf.loc[df[\"Year\"] == year, \"TotalSeconds\"] = ts\n",
    "\n",
    "\t\tdf_rankings.sort_values([\"Year\", \"Rank\"], axis=0, ascending=True, inplace=True)\n",
    "\t\tdf_rankings = df_rankings.reset_index(drop=True)\n",
    "\n",
    "\t\tdf_stages.sort_values([\"Year\", \"Stages\"], axis=0, ascending=True, inplace=True)\n",
    "\t\tdf_stages = df_stages.reset_index(drop=True)\n",
    "\n",
    "\t\tdf_all_rankings.sort_values(\n",
    "\t\t\t[\"Year\", \"Stages\", \"Ranking type\", \"Rank\"],\n",
    "\t\t\taxis=0,\n",
    "\t\t\tascending=True,\n",
    "\t\t\tinplace=True,\n",
    "\t\t)\n",
    "\t\tdf_all_rankings = df_all_rankings.reset_index(drop=True)\n",
    "\n",
    "\t\treturn df_rankings, df_all_rankings, df_stages\n",
    "\n",
    "\tdef _get_seconds(self, row: str, mode: str) -> int:\n",
    "\t\tif type(row) == float and np.isnan(row):\n",
    "\t\t\treturn 0\n",
    "\t\telif \"h\" in row:\n",
    "\t\t\tval = sum(\n",
    "\t\t\t\tto_seconds * int(t)\n",
    "\t\t\t\tfor to_seconds, t in zip(\n",
    "\t\t\t\t\t[3600, 60, 1],\n",
    "\t\t\t\t\trow.replace(\"h\", \":\")\n",
    "\t\t\t\t\t.replace(\"'\", \":\")\n",
    "\t\t\t\t\t.replace('\"', \":\")\n",
    "\t\t\t\t\t.replace(\" \", \"\")\n",
    "\t\t\t\t\t.replace(\"+\", \"\")\n",
    "\t\t\t\t\t.replace(\"-\", \"0\")\n",
    "\t\t\t\t\t.split(\":\"),\n",
    "\t\t\t\t)\n",
    "\t\t\t)\n",
    "\t\telse:\n",
    "\t\t\t# Try using the library dateutil.parser to parse the time\n",
    "\t\t\ttry:\n",
    "\t\t\t\tval = pd.to_datetime(row).hour * 3600 + pd.to_datetime(row).minute * 60 + pd.to_datetime(row).second\n",
    "\t\t\texcept:\n",
    "\t\t\t\tval = 0\n",
    "\n",
    "\t\tif (mode == \"Gap\") and val > 180000:\n",
    "\t\t\treturn 0\n",
    "\t\telse:\n",
    "\t\t\treturn val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Men\n",
    "downloader = Downloader(history_page=\"https://www.letour.fr/en/history\")\n",
    "df_stages, df_rankings, df_all_rankings = await downloader.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
