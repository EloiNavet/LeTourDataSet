{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from requests_html import AsyncHTMLSession\n",
    "from bs4 import BeautifulSoup, Tag\n",
    "from io import StringIO\n",
    "\n",
    "from rich.progress import track\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Downloader:\n",
    "\tdef __init__(\n",
    "\t\tself,\n",
    "\t\thistory_page=\"https://www.letour.fr/en/history\",\n",
    "\t\theaders={\n",
    "\t\t\t\"Accept\": \"text/html\",\n",
    "\t\t\t\"User-Agent\": \"python-requests/1.2.0\",\n",
    "\t\t\t\"Accept-Charset\": \"utf-8\",\n",
    "\t\t\t\"accept-encoding\": \"deflate, br\",\n",
    "\t\t},\n",
    "\t) -> None:\n",
    "\t\tself._prefix = \"http://www.letour.fr\"\n",
    "\t\tself._links: list[str] = self._get_urls(history_page, headers)\n",
    "\t\tself._ranking_types = {\n",
    "\t\t\t# \"Individual (General)\": \"itg\",\n",
    "\t\t\t\"Individual (Stage)\": \"ite\",\n",
    "\t\t\t# \"Points (General)\": \"ipg\",\n",
    "\t\t\t\"Points (Stage)\": \"ipe\",\n",
    "\t\t\t# \"Climber (General)\": \"img\",\n",
    "\t\t\t\"Climber (Stage)\": \"ime\",\n",
    "\t\t\t# \"Youth (General)\": \"ijg\",\n",
    "\t\t\t\"Youth (Stage)\": \"ije\",\n",
    "\t\t\t# \"Combative (General)\": \"icg\",\n",
    "\t\t\t\"Combative (Stage)\": \"ice\",\n",
    "\t\t\t# \"Team (General)\": \"etg\",\n",
    "\t\t\t\"Team (Stage)\": \"ete\",\n",
    "\t\t}\n",
    "\n",
    "\tdef _get_urls(self, history_page: str, headers: dict[str, str]) -> list[str]:\n",
    "\t\tstring = str(\n",
    "\t\t\tBeautifulSoup(\n",
    "\t\t\t\trequests.get(history_page, allow_redirects=True, headers=headers).text,\n",
    "\t\t\t\t\"html.parser\",\n",
    "\t\t\t)\n",
    "\t\t)\n",
    "\t\tpattern = r'data-tabs-ajax=\"([^\"]+)\"'\n",
    "\t\tmatches = re.findall(pattern, string)\n",
    "\t\tmatches = matches[::-1]\n",
    "\t\tlogging.debug(\n",
    "\t\t\t\"Matches found in the history page:\\n{}\".format(\"\\n\".join(matches))\n",
    "\t\t)\n",
    "\t\treturn matches\n",
    "\n",
    "\tasync def run(self) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "\t\tstages_list: list[pd.DataFrame] = []\n",
    "\t\trankings_list: list[pd.DataFrame] = []\n",
    "\t\tall_rankings_list: list[pd.DataFrame] = []\n",
    "\t\tlogging.debug(\"Links:\\n{}\".format(\"\\n\".join(self._links)))\n",
    "\t\tfor link in track(self._links, \"Downloading historical data...\"):\n",
    "\t\t\tlogging.info(\"Downloading data from {}\".format(self._prefix + link))\n",
    "\t\t\tsoup, year, distance = self._get_soup_year_distance(self._prefix + link)\n",
    "\n",
    "\t\t\tlogging.info(\"Parsing data from {}\".format(self._prefix + link))\n",
    "\t\t\tstages = self._get_stages(soup, year, distance)\n",
    "\t\t\tfinal_rankings = self._get_rankings(soup)\n",
    "\n",
    "\t\t\tlogging.info(\"Fetching yearly TDF URLs from {}\".format(self._prefix + link))\n",
    "\t\t\tselections_urls = await self._fetch_yearly_tdf_urls(self._prefix + link)\n",
    "\t\t\tintermediate_rankings = await self._get_all_rankings(selections_urls[\"Ranking\"], len(stages))\n",
    "\t\t\tstages_winners = self._get_stages_winners(selections_urls[\"Stages winners\"])\n",
    "\t\t\t# teams = self._get_teams(selections_urls[\"Starters\"])\n",
    "\t\t\tjersey_wearers = self._get_jersey_wearers(selections_urls[\"Jersey wearers\"])\n",
    "\n",
    "\t\t\t# Update the dataframe stages by merging on 'Stages' using the stages_winners dataframe and the jersey_wearers dataframe\n",
    "\t\t\tstages = pd.merge(stages, stages_winners, on='Stages', how='left')\n",
    "\t\t\t# Drop 'Parcours' column\n",
    "\t\t\tstages = stages.drop(columns='Parcours')\n",
    "\t\t\tstages = pd.merge(stages, jersey_wearers, on='Stages', how='left')\n",
    "\t\t\t# Make the first letter of each word in the fields of the columns that contains 'Winner' or 'Jersey' in their names uppercase and the rest lowercase using title() method\n",
    "\t\t\tcols = [col for col in stages.columns if 'winner' in col.lower() or 'jersey' in col.lower()]\n",
    "\t\t\tstages[cols] = stages[cols].apply(lambda x: x.str.title())\n",
    "\t\t\t# stages['Team'] = stages['Winner of stage'].apply(lambda x: x.split('(')[1].replace(')', ''))\n",
    "\t\t\t# stages['Winner of stage'] = stages['Winner of stage'].apply(lambda x: x.split('(')[0].strip())\n",
    "\n",
    "\t\t\tlogging.info(\"Cleaning up data from {}\".format(self._prefix + link))\n",
    "\t\t\tdf_ranking, df_all_rankings, df_stage = self._cleanup(\n",
    "\t\t\t\tstages,\n",
    "\t\t\t\tfinal_rankings,\n",
    "\t\t\t\tintermediate_rankings,\n",
    "\t\t\t\tyear,\n",
    "\t\t\t\tdistance,\n",
    "\t\t\t)\n",
    "\t\t\tlogging.info(\"Data from {} cleaned up\".format(self._prefix + link)) \n",
    "\t\t\tstages_list.append(df_stage)\n",
    "\t\t\trankings_list.append(df_ranking)\n",
    "\t\t\tall_rankings_list.append(df_all_rankings)\n",
    "\n",
    "\t\t\t# except Exception as e:\n",
    "\t\t\t# \tlogging.warning(link)\n",
    "\t\t\t# \tlogging.warning(e)\n",
    "\n",
    "\t\tlogging.debug(\"Stage list:\\n{}\".format(stages_list))\n",
    "\t\tlogging.debug(\"Ranking list:\\n{}\".format(rankings_list))\n",
    "\t\tdf_stages = pd.concat(stages_list, ignore_index=True)\n",
    "\t\tdf_rankings = pd.concat(rankings_list, ignore_index=True)\n",
    "\t\tdf_all_rankings = pd.concat(all_rankings_list, ignore_index=True)\n",
    "\n",
    "\t\treturn df_stages, df_rankings, df_all_rankings\n",
    "\n",
    "\tdef _get_soup_year_distance(self, link: str) -> tuple[Tag, int, int]:\n",
    "\t\tresult = requests.get(link, allow_redirects=True)\n",
    "\t\ttext = result.text\n",
    "\t\tstatus = result.status_code\n",
    "\t\tlogging.info(link + \" ==> HTTP STATUS = \" + str(status))\n",
    "\n",
    "\t\tsoup = BeautifulSoup(text, \"html.parser\")\n",
    "\t\tyear_tag = soup.find(\"h3\")\n",
    "\t\tif year_tag is None:\n",
    "\t\t\traise Exception(\"Could not parse year.\")\n",
    "\t\tyear = int(year_tag.text[-4:])\n",
    "\t\tdistance = soup.select(\"[class~=statsInfos__number]\")[1].contents\n",
    "\t\tdistance = int(str(distance[0]).replace(\" \", \"\"))\n",
    "\t\treturn soup, year, distance\n",
    "\n",
    "\tdef _get_stages(self, soup: Tag, year: int, distance: int) -> pd.DataFrame:\n",
    "\t\tselect_tag = soup.find(\"select\")\n",
    "\t\tif not isinstance(select_tag, Tag):\n",
    "\t\t\traise Exception(\"Can't find `select`.\")\n",
    "\n",
    "\t\tdf_stages = pd.DataFrame(\n",
    "\t\t\t[[year, distance, option.text] for option in select_tag.find_all(\"option\")],\n",
    "\t\t\tcolumns=[\"Year\", \"TotalTDFDistance\", \"Stage\"],\n",
    "\t\t)\n",
    "\n",
    "\t\t# For the column Stage, it is formated like 'Stage 1 : Paris > Lyon' (so \"Stage [Number of stage] : [Start city] > [End city]\")\n",
    "\t\t# We will split this column into 'Stage number', 'Start city' and 'End city'\n",
    "\t\tdf_stages[\"Stage number\"] = df_stages[\"Stage\"].apply(\n",
    "\t\t\tlambda x: int(x.split(\":\")[0].split(\" \")[1])\n",
    "\t\t)\n",
    "\t\tdf_stages[\"Start\"] = df_stages[\"Stage\"].apply(\n",
    "\t\t\tlambda x: x.split(\":\")[1].split(\">\")[0].strip()\n",
    "\t\t)\n",
    "\t\tdf_stages[\"End\"] = df_stages[\"Stage\"].apply(\n",
    "\t\t\tlambda x: x.split(\":\")[1].split(\">\")[1].strip()\n",
    "\t\t)\n",
    "\t\tdf_stages.drop(columns=\"Stage\", inplace=True)\n",
    "\t\tdf_stages.rename(columns={\"Stage number\": \"Stages\"}, inplace=True)\n",
    "\t\tdf_stages = df_stages[[\"Year\", \"TotalTDFDistance\", \"Stages\", \"Start\", \"End\"]]\n",
    "\t\treturn df_stages\n",
    "\n",
    "\tdef _get_stages_winners(self, winners_link: str) -> pd.DataFrame:\n",
    "\t\tresponse = requests.get(winners_link)\n",
    "\t\tresponse.raise_for_status()\n",
    "\t\trank_html = response.content\n",
    "\t\tsoup = BeautifulSoup(rank_html, \"html.parser\")\n",
    "\t\tstages_winners = soup.find(\"table\")\n",
    "\t\thtml_string = str(stages_winners)\n",
    "\t\thtml_io = StringIO(html_string)\n",
    "\t\tdf_stages_winners = pd.read_html(html_io)[0]\n",
    "\t\tdf_stages_winners.drop(columns=\"Last km\", inplace=True)\n",
    "\t\treturn df_stages_winners\n",
    "\n",
    "\tdef _get_teams(self, starters_link: str) -> pd.DataFrame:\n",
    "\t\tresponse = requests.get(starters_link)\n",
    "\t\tresponse.raise_for_status()\n",
    "\t\tstarter_html = response.content\n",
    "\t\tsoup = BeautifulSoup(starter_html, \"html.parser\")\n",
    "\t\tcompetitors = []\n",
    "\t\tteam_blocks = soup.find(\"div\", class_=\"list list--competitors\").find_all(\"h3\", class_=\"list__heading\")\n",
    "\n",
    "\t\tfor team_block in team_blocks:\n",
    "\t\t\tteam_name = team_block.text.strip()\n",
    "\t\t\tlist_box = team_block.find_next_sibling(\"div\", class_=\"list__box\")\n",
    "\t\t\tcompetitor_items = list_box.find_all(\"li\", class_=\"list__box__item\")\n",
    "\n",
    "\t\t\tfor item in competitor_items:\n",
    "\t\t\t\tbib = (\n",
    "\t\t\t\t\titem.find(\"span\", class_=\"bib\").text\n",
    "\t\t\t\t\tif item.find(\"span\", class_=\"bib\")\n",
    "\t\t\t\t\telse None\n",
    "\t\t\t\t)\n",
    "\t\t\t\tname = (\n",
    "\t\t\t\t\titem.find(\"a\", class_=\"runner__link\").text.strip()\n",
    "\t\t\t\t\tif item.find(\"a\", class_=\"runner__link\")\n",
    "\t\t\t\t\telse None\n",
    "\t\t\t\t)\n",
    "\t\t\t\tcountry = (\n",
    "\t\t\t\t\titem.find(\"span\", class_=\"flag js-display-lazy\")[\n",
    "\t\t\t\t\t\t\"data-class\"\n",
    "\t\t\t\t\t].split(\"--\")[-1]\n",
    "\t\t\t\t\tif item.find(\"span\", class_=\"flag js-display-lazy\")\n",
    "\t\t\t\t\telse None\n",
    "\t\t\t\t)\n",
    "\n",
    "\t\t\t\tif bib and name:\n",
    "\t\t\t\t\tcompetitors.append(\n",
    "\t\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\t\"Team\": team_name,\n",
    "\t\t\t\t\t\t\t\"Bib\": bib,\n",
    "\t\t\t\t\t\t\t\"Name\": name,\n",
    "\t\t\t\t\t\t\t\"Country\": country,\n",
    "\t\t\t\t\t\t}\n",
    "\t\t\t\t\t)\n",
    "\n",
    "\t\treturn pd.DataFrame(competitors)\n",
    "\n",
    "\tdef _get_jersey_wearers(self, jersey_link: str) -> pd.DataFrame:\n",
    "\n",
    "\t\tresponse = requests.get(jersey_link)\n",
    "\t\tresponse.raise_for_status()\n",
    "\t\tjersey_html = response.content\n",
    "\t\tsoup = BeautifulSoup(jersey_html, \"html.parser\")\n",
    "\t\tjersey_wearers = soup.find(\"table\")\n",
    "\t\thtml_string = str(jersey_wearers)\n",
    "\t\thtml_io = StringIO(html_string)\n",
    "\t\tdf_jersey_wearers = pd.read_html(html_io)[0]\n",
    "\t\treturn df_jersey_wearers\n",
    "\n",
    "\tdef _add_bib_number(self, soup: Tag, df_rankings: pd.DataFrame) -> pd.DataFrame:\n",
    "\t\t# Manually add the bib numbers because they are not in the rankings table\n",
    "\t\tbibs = re.findall(r'data-bib=\"([^\"]+)\"', str(soup))\n",
    "\t\tbibs = [int(bib.replace(\"#\", \"\")) for bib in bibs]\n",
    "\t\tdf_rankings.insert(2, \"Rider No.\", bibs)\n",
    "\t\treturn df_rankings\n",
    "\n",
    "\tdef _get_rankings(self, soup: Tag) -> pd.DataFrame:\n",
    "\t\t\"\"\"Get the rankings for a given year\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\tsoup (Tag): BeautifulSoup object of the ranking page\n",
    "\n",
    "\t\tReturns:\n",
    "\t\t\tpd.DataFrame: DataFrame containing the rankings for the given year\n",
    "\t\t\"\"\"\n",
    "\t\trankingTable = soup.find(\"table\")\n",
    "\t\thtml_string = str(rankingTable)\n",
    "\t\thtml_io = StringIO(html_string)\n",
    "\t\tdf_rankings = pd.read_html(html_io)[0]\n",
    "\t\tself._add_bib_number(soup, df_rankings)\n",
    "\t\treturn df_rankings\n",
    "\n",
    "\tasync def _fetch_yearly_tdf_urls(self, year_url: str) -> dict[str, str]:\n",
    "\t\tsession = AsyncHTMLSession()\n",
    "\t\tresponse = await session.get(year_url)\n",
    "\t\tawait response.html.arender(timeout=20)\n",
    "\n",
    "\t\tsoup = BeautifulSoup(response.html.html, \"html.parser\")\n",
    "\n",
    "\t\tbuttons = soup.find_all(\n",
    "\t\t\t\"button\", class_=\"tabs__item btn js-tabs-nested\"\n",
    "\t\t) + soup.find_all(\"button\", class_=\"tabs__item btn js-tabs-nested is-active\")\n",
    "\n",
    "\t\tselections_urls = {\n",
    "\t\t\tbutton.get_text(strip=True): f\"{self._prefix}{button['data-tabs-ajax']}\"\n",
    "\t\t\tfor button in buttons\n",
    "\t\t}\n",
    "\n",
    "\t\treturn selections_urls\n",
    "\n",
    "\tasync def _get_all_rankings(self, ranking_link: str, n_stages: int) -> pd.DataFrame:\n",
    "\t\t\"\"\"Get all rankings for a given year. Currently implemented ranking types are 'Individual (Stage)', 'Points (Stage)', 'Climber (Stage)', 'Youth (Stage)', 'Combative (Stage)', 'Team (Stage)'\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\tranking_link (str): link to the ranking page\n",
    "\t\t\tn_stages (int): number of stages in this edition of the Tour de France\n",
    "\n",
    "\t\tRaises:\n",
    "\t\t\tNotImplementedError: If the ranking type is not implemented\n",
    "\n",
    "\t\tReturns:\n",
    "\t\t\tpd.DataFrame: DataFrame containing all rankings for the given year\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tdf_all_stages = pd.DataFrame(\n",
    "\t\t\tcolumns=[\n",
    "\t\t\t\t\"Stages\",\n",
    "\t\t\t\t\"Ranking type\",\n",
    "\t\t\t\t\"Checkpoint\" \"Rank\",\n",
    "\t\t\t\t\"Rider\",\n",
    "\t\t\t\t\"Team\",\n",
    "\t\t\t\t\"Times\",\n",
    "\t\t\t\t\"Points\",\n",
    "\t\t\t\t\"Gap\",\n",
    "\t\t\t\t\"B\",\n",
    "\t\t\t\t\"P\",\n",
    "\t\t\t]\n",
    "\t\t)\n",
    "\n",
    "\t\tfor stage_number in range(1, n_stages + 1):\n",
    "\t\t\tfor ranking_type_name, ranking_type_idx in self._ranking_types.items():\n",
    "\t\t\t\tranking_url = (\n",
    "\t\t\t\t\tf\"{ranking_link}?stage={stage_number}&type={ranking_type_idx}\"\n",
    "\t\t\t\t)\n",
    "\n",
    "\t\t\t\tresponse = requests.get(ranking_url)\n",
    "\t\t\t\tresponse.raise_for_status()\n",
    "\t\t\t\trank_html = response.content\n",
    "\n",
    "\t\t\t\trank_soup = BeautifulSoup(rank_html, \"html.parser\")\n",
    "\n",
    "\t\t\t\t# Get the ranking table\n",
    "\t\t\t\tranking_table = rank_soup.find(\n",
    "\t\t\t\t\t\"table\", {\"class\": \"rankingTable rtable js-extend-target\"}\n",
    "\t\t\t\t)\n",
    "\t\t\t\trows = ranking_table.find_all(\"tr\")\n",
    "\t\t\t\tif len(rows) == 1:\n",
    "\t\t\t\t\tprint(f\"No ranking for {ranking_type_name} on stage {stage_number}\")\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\trankings = []\n",
    "\t\t\t\tfor row in rows[1:]:\n",
    "\t\t\t\t\tcols = row.find_all(\"td\")\n",
    "\t\t\t\t\tif \"ite\" in ranking_type_idx:\n",
    "\t\t\t\t\t\tranking = {\n",
    "\t\t\t\t\t\t\t\"Rank\": cols[0].text.strip(),\n",
    "\t\t\t\t\t\t\t\"Rider\": cols[1].text.strip(),\n",
    "\t\t\t\t\t\t\t\"Team\": cols[2].text.strip(),\n",
    "\t\t\t\t\t\t\t\"Times\": cols[3].text.strip(),\n",
    "\t\t\t\t\t\t\t\"Gap\": cols[4].text.strip(),\n",
    "\t\t\t\t\t\t\t\"B\": cols[5].text.strip(),\n",
    "\t\t\t\t\t\t\t\"P\": cols[6].text.strip(),\n",
    "\t\t\t\t\t\t}\n",
    "\t\t\t\t\telif \"ipe\" in ranking_type_idx:\n",
    "\t\t\t\t\t\tcheckpoint = None\n",
    "\t\t\t\t\t\tif len(cols) == 1:\n",
    "\t\t\t\t\t\t\tcheckpoint = cols[0].text.strip()\n",
    "\t\t\t\t\t\t\tcontinue\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tranking = {\n",
    "\t\t\t\t\t\t\t\t\"Rank\": cols[0].text.strip(),\n",
    "\t\t\t\t\t\t\t\t\"Rider\": cols[1].text.strip(),\n",
    "\t\t\t\t\t\t\t\t\"Team\": cols[2].text.strip(),\n",
    "\t\t\t\t\t\t\t\t\"Points\": cols[3].text.strip(),\n",
    "\t\t\t\t\t\t\t\t\"B\": cols[4].text.strip(),\n",
    "\t\t\t\t\t\t\t\t\"Checkpoint\": checkpoint,\n",
    "\t\t\t\t\t\t\t}\n",
    "\t\t\t\t\telif \"ime\" in ranking_type_idx:\n",
    "\t\t\t\t\t\tcheckpoint = None\n",
    "\t\t\t\t\t\tif len(cols) == 1:\n",
    "\t\t\t\t\t\t\tcheckpoint = cols[0].text.strip()\n",
    "\t\t\t\t\t\t\tcontinue\n",
    "\t\t\t\t\t\tranking = {\n",
    "\t\t\t\t\t\t\t\"Rank\": cols[0].text.strip(),\n",
    "\t\t\t\t\t\t\t\"Rider\": cols[1].text.strip(),\n",
    "\t\t\t\t\t\t\t\"Team\": cols[2].text.strip(),\n",
    "\t\t\t\t\t\t\t\"Points\": cols[3].text.strip(),\n",
    "\t\t\t\t\t\t\t\"Checkpoint\": checkpoint,\n",
    "\t\t\t\t\t\t}\n",
    "\t\t\t\t\telif \"ije\" in ranking_type_idx or \"ice\" in ranking_type_idx:\n",
    "\t\t\t\t\t\tranking = {\n",
    "\t\t\t\t\t\t\t\"Rank\": cols[0].text.strip(),\n",
    "\t\t\t\t\t\t\t\"Rider\": cols[1].text.strip(),\n",
    "\t\t\t\t\t\t\t\"Team\": cols[2].text.strip(),\n",
    "\t\t\t\t\t\t\t\"Times\": cols[3].text.strip(),\n",
    "\t\t\t\t\t\t\t\"Gap\": cols[4].text.strip(),\n",
    "\t\t\t\t\t\t}\n",
    "\t\t\t\t\telif \"ete\" in ranking_type_idx:\n",
    "\t\t\t\t\t\tranking = {\n",
    "\t\t\t\t\t\t\t\"Rank\": cols[0].text.strip(),\n",
    "\t\t\t\t\t\t\t\"Team\": cols[1].text.strip(),\n",
    "\t\t\t\t\t\t\t\"Times\": cols[2].text.strip(),\n",
    "\t\t\t\t\t\t\t\"Gap\": cols[3].text.strip(),\n",
    "\t\t\t\t\t\t}\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\traise NotImplementedError(\n",
    "\t\t\t\t\t\t\tf\"Ranking type {ranking_type_name} not implemented\"\n",
    "\t\t\t\t\t\t)\n",
    "\n",
    "\t\t\t\t\trankings.append(ranking)\n",
    "\t\t\t\tdf_stage = pd.DataFrame(rankings)\n",
    "\n",
    "\t\t\t\tdf_stage[\"Stages\"] = stage_number\n",
    "\t\t\t\tdf_stage[\"Ranking type\"] = ranking_type_name\n",
    "\n",
    "\t\t\t\tdf_all_stages = pd.concat([df_all_stages, df_stage], ignore_index=True)\n",
    "\n",
    "\t\treturn df_all_stages\n",
    "\n",
    "\tdef _cleanup(\n",
    "\t\tself,\n",
    "\t\tdf_stages: pd.DataFrame,\n",
    "\t\tdf_rankings: pd.DataFrame,\n",
    "\t\t  df_all_rankings: pd.DataFrame,\n",
    "\t\tyear: int,\n",
    "\t\tdistance: int,\n",
    "\t) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "\n",
    "\t\t# Odd years \n",
    "\t\tpoint_years = [1907, 1909, 1910, 1911, 1912]\n",
    "\t\tnull_years = [1905, 1906, 1908]\n",
    "  \n",
    "\t\tdf_rankings[\"TotalSeconds\"] = df_rankings[\"Times\"].apply(\n",
    "\t\t\tlambda x: self._get_seconds(x, \"Total\")\n",
    "\t\t)\n",
    "\t\tdf_rankings[\"GapSeconds\"] = df_rankings[\"Gap\"].apply(\n",
    "\t\t\tlambda x: self._get_seconds(x, \"Gap\")\n",
    "\t\t)\n",
    "  \n",
    "\t\tfor df in [df_rankings, df_all_rankings]:\n",
    "\t\t\t# Remainder of df_rankings.columns : 'Rank', 'Rider', 'Rider No.', 'Team', 'Times', 'Gap', 'B', 'P'\n",
    "\t\t\t# Remainder of df_all_rankings.columns : 'Stages', 'Ranking type', 'CheckpointRank', 'Rider', 'Team', 'Times', 'Points', 'Gap', 'B', 'P', 'Rank', 'Checkpoint'\n",
    "\t\t\tdf[\"Year\"] = year\n",
    "\t\t\tdf[\"Distance (km)\"] = distance\n",
    "\t\t\tdf[\"Number of stages\"] = len(df_stages)\n",
    "\t  \n",
    "\t\t\tdf[\"ResultType\"] = \"time\"\n",
    "\t\t\tdf.loc[df[\"Year\"].isin(null_years), \"ResultType\"] = \"null\"\n",
    "\t\t\tdf.loc[df[\"Year\"].isin(point_years), \"ResultType\"] = \"points\"\n",
    "\n",
    "\t\t\tif year in [2006, 1997]:\n",
    "\t\t\t\ttmp = df[df[\"Year\"] == year].reset_index()\n",
    "\t\t\t\tts = np.array(tmp[\"TotalSeconds\"])\n",
    "\t\t\t\tgs = np.array(tmp[\"GapSeconds\"])\n",
    "\t\t\t\tts[1:] = ts[0] + gs[1:]\n",
    "\t\t\t\tdf.loc[df[\"Year\"] == year, \"TotalSeconds\"] = ts\n",
    "\n",
    "\t\tdf_rankings.sort_values([\"Year\", \"Rank\"], axis=0, ascending=True, inplace=True)\n",
    "\t\tdf_rankings = df_rankings.reset_index(drop=True)\n",
    "\n",
    "\t\tdf_stages.sort_values([\"Year\", \"Stages\"], axis=0, ascending=True, inplace=True)\n",
    "\t\tdf_stages = df_stages.reset_index(drop=True)\n",
    "  \n",
    "\t\tdf_all_rankings.sort_values([\"Year\", \"Stages\", \"Ranking type\", \"Rank\"], axis=0, ascending=True, inplace=True)\n",
    "\t\tdf_all_rankings = df_all_rankings.reset_index(drop=True)\n",
    "  \n",
    "\t\treturn df_rankings, df_all_rankings, df_stages\n",
    "\n",
    "\tdef _get_seconds(self, row: str, mode: str) -> int:\n",
    "\t\tval = sum(\n",
    "\t\t\tto_seconds * int(t)\n",
    "\t\t\tfor to_seconds, t in zip(\n",
    "\t\t\t\t[3600, 60, 1],\n",
    "\t\t\t\trow.replace(\"h\", \":\")\n",
    "\t\t\t\t.replace(\"'\", \":\")\n",
    "\t\t\t\t.replace('\"', \":\")\n",
    "\t\t\t\t.replace(\" \", \"\")\n",
    "\t\t\t\t.replace(\"+\", \"\")\n",
    "\t\t\t\t.replace(\"-\", \"0\")\n",
    "\t\t\t\t.split(\":\"),\n",
    "\t\t\t)\n",
    "\t\t)\n",
    "\n",
    "\t\tif (mode == \"Gap\") and val > 180000:\n",
    "\t\t\treturn 0\n",
    "\t\telse:\n",
    "\t\t\treturn val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Men\n",
    "downloader = Downloader(history_page=\"https://www.letour.fr/en/history\")\n",
    "# links = downloader._get_urls(\"https://www.letour.fr/en/history\", headers={\"Accept\": \"text/html\", \"User-Agent\": \"python-requests/1.2.0\", \"Accept-Charset\": \"utf-8\", \"accept-encoding\": \"deflate, br\"})\n",
    "# print(\"Links:\", links)\n",
    "# soup, year, distance = downloader._get_soup_year_distance(downloader._prefix+links[-1])\n",
    "# print(\"Year:\", year, \"Distance:\", distance)\n",
    "# stages = downloader._get_stages(soup, year, distance)\n",
    "# print(\"Stages:\", stages)\n",
    "# selections_urls = await downloader._fetch_yearly_tdf_urls(downloader._prefix+links[-1])\n",
    "# print(\"Selections URLs:\", selections_urls)\n",
    "# intermediate_rankings = await downloader._get_all_rankings(selections_urls[\"Ranking\"], len(stages))\n",
    "# print(\"All rankings for last year:\", intermediate_rankings)\n",
    "# stages_winners = downloader._get_stages_winners(selections_urls[\"Stages winners\"])\n",
    "# print(\"Stages winners:\", stages_winners)\n",
    "# teams = downloader._get_teams(selections_urls[\"Starters\"])\n",
    "# print(\"Teams:\", teams)\n",
    "# jersey_wearers = downloader._get_jersey_wearers(selections_urls[\"Jersey wearers\"])\n",
    "# print(\"Jersey wearers:\", jersey_wearers)\n",
    "df_stages, df_rankings, df_all_rankings = await downloader.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
